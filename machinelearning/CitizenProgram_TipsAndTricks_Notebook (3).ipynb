{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful lines of code when going through the Data Science Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # removes a column from a pandas dataframe if the percentage of missing values is greater than a given `threshold` value. \n",
    "    # user provides a `unique_value_threshold` which removes a column if the percentage of unique values in that column is below the `unique_value_threshold`.   \n",
    "def drop_columns(input_df, threshold, unique_value_threshold):\n",
    "    df = input_df.copy()\n",
    "    columns = df.columns\n",
    "    for i in columns:\n",
    "        unique= (df[i].nunique()/df[i].dropna().shape[0])*100\n",
    "        missing = df[i].isnull().sum() * 100 / len(df[i])\n",
    "        if unique < unique_value_threshold:\n",
    "            del df[i]\n",
    "        if missing > threshold:\n",
    "            del df[i]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input a column and return the count of missing values:\n",
    "def total_missing(df,column_name):\n",
    "    for col in df.columns: \n",
    "        if column_name in col:\n",
    "            total = df[col].isnull().sum()\n",
    "            ret_string = str(column_name) + \" has \" + str(total) + \" missing values\"\n",
    "    return str(ret_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns as output the mean if the specified column is numerical and return a list of the mode(s) otherwise.\n",
    "def calc_mean_mode(df, column_name):\n",
    "    # your code here\n",
    "    for col in df.columns:\n",
    "        if column_name in col:\n",
    "            if df[col].dtype != 'object':\n",
    "                ret_value = round(df[col].mean(),2) #df[col].fillna(df[col].mean())\n",
    "            else:\n",
    "                ret_value = list(df[col].mode())\n",
    "            return ret_value\n",
    "    if column_name not in df:\n",
    "        return ValueError('could not find column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples of how to manipulate datetime object:\n",
    "train_data['Year']  = train_data['time'].astype('datetime64').dt.year\n",
    "train_data['Month_of_year']  = train_data['time'].astype('datetime64').dt.month\n",
    "train_data['Week_of_year'] = train_data['time'].astype('datetime64').dt.weekofyear\n",
    "train_data['Day_of_year']  = train_data['time'].astype('datetime64').dt.dayofyear\n",
    "train_data['Day_of_month']  = train_data['time'].astype('datetime64').dt.day\n",
    "train_data['Day_of_week'] = train_data['time'].astype('datetime64').dt.dayofweek\n",
    "train_data['Hour_of_week'] = ((train_data['time'].astype('datetime64').dt.dayofweek) * 24 + 24) - (24 - train_data['time'].astype('datetime64').dt.hour)\n",
    "train_data['Hour_of_day']  = train_data['time'].astype('datetime64').dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to drop multiple columns from a dataframe:\n",
    "train_data = train_data.drop(columns=['Week_of_year','Day_of_year','Hour_of_week','time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### example of how to see interaction between categorical features\n",
    "import pandas as pd\n",
    "title_df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/regression_sprint/titanic_train_title.csv')\n",
    "pd.crosstab(index=title_df['Title'], columns=title_df['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## encode categorical variables for input into ML Model:\n",
    "def dummy_encode_titles(input_df):\n",
    "    # your code here\n",
    "    df = input_df.copy()\n",
    "    static = pd.get_dummies(df['Title'], dummy_na=False, drop_first=True, prefix_sep='_',prefix='Title')\n",
    "    return static\n",
    "\n",
    "encode_df = dummy_encode_titles(title_df)\n",
    "dummy_cols = [col for col in encode_df if col.startswith('Title')]\n",
    "encode_df[dummy_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# five number summary taking a list as input\n",
    "from numpy import percentile\n",
    "def five_num_summary(items):\n",
    "    # your code here\n",
    "    d = dict()\n",
    "    d['max'] = round(max(items),2)\n",
    "    d['median'] = round(percentile(items, [50])[0],2)\n",
    "    d['min'] = round(min(items),2)\n",
    "    d['q1'] = round(percentile(items, [25])[0],2)\n",
    "    d['q3'] = round(percentile(items, [75])[0], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import matplotlib.pyplot as plt #used for plotting data \n",
    "import numpy as np #used for mathematical operations\n",
    "import pandas as pd #used to loading CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a donut chart\n",
    "\n",
    "# Initially we create a pie chart as the base of our donut chart. \n",
    "plt.pie(tips, labels=meal_time, autopct='%1.1f%%', startangle=140)\n",
    "\n",
    "# Next, we create a circle at the center of the base plot\n",
    "centre_circle = plt.Circle((0,0),0.77, fc='white',linewidth=1.25)\n",
    "fig = plt.gcf() # <-- Matplotlib command to get the current figure for further manipulation. \n",
    "# Add the circle to our base pie chart\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#line graph\n",
    "total_meals = {'31/01/1990': 1340, '28/02/1990': 1338, '31/03/1990': 1330, '30/04/1990': 1328, '31/05/1990': 1335, '30/06/1990': 1335}\n",
    "dates = list(total_meals.keys()) # Extract the dates (the dictionary keys of our data in this case)\n",
    "x_ax = [date[3:5] for date in dates] # Extract the month from each date string\n",
    "y_ax = list(total_meals.values()) # Extract the total number of meals consumed on each date as a Python list\n",
    "\n",
    "# Plot the line graph\n",
    "plt.plot(x_ax, y_ax, color='green') \n",
    "\n",
    "# Set axis and graph titles\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Total meals sold')\n",
    "plt.title('Line Graph Showing the Total Number of Meals Sold Over the First 6 Months of 1990 \\n')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar plot\n",
    "plt.bar(week_day, bill, color= 'orange')\n",
    "\n",
    "# Set x and y axis titles\n",
    "plt.ylabel('Total Bill')\n",
    "plt.xlabel('\\n Days of the Week(Thur-Sun)') # Note: '\\n' creates a newline (try removing it and see what happens)  \n",
    "\n",
    "# Set graph title\n",
    "plt.title('Total bill of customers for Thur-Sun \\n')\n",
    "\n",
    "# Show graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "# For this plot, we need to access the underlying Axes object used to create our chart. \n",
    "# To display our data correctly, we also set the `figsize` argument to increase the size of the plot. \n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "# Create the scatter plot, with the 'size' variable being coded as the marker colour. \n",
    "# We set the `alpha` parameter to make the markers slightly transparent to view overlapping points. \n",
    "scatter = ax.scatter(df['total_bill'], df['tip'], c=df['size'], alpha=0.8)\n",
    "\n",
    "# We now create our legend based upon the underlying group size and colour assignments.\n",
    "ax.legend(*scatter.legend_elements(), loc=\"best\", title=\"Group Size\")\n",
    "\n",
    "# Set graph and axis titles\n",
    "plt.title('Scatter Plot Showing the Average Amount Tipped vs Group Size \\n')\n",
    "plt.xlabel('Bill Total ($)')\n",
    "plt.ylabel('Amount Tipped ($)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart\n",
    "modelling_data['target'].value_counts().plot(kind=\"pie\", autopct=\"%.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 box plots side by side\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "sns.boxplot(ax=axes[0], data=modelling_data_0, x='target', y='GSM_RECHARGE_D_M1', showfliers = False).set_title('GSM recharge')\n",
    "sns.boxplot(ax=axes[1], data=modelling_data_0, x='target', y='MPESA_RECHARGE_D_M1', showfliers = False).set_title('Mpesa recharge')\n",
    "sns.boxplot(ax=axes[2], data=modelling_data_0, x='target', y='gsm_tenure', showfliers = False).set_title('Tenure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(modelling_data_111.drop(['Unnamed: 0','sample_id','rag_opt_year_month','rag_opt_year_month_str', 'Age_at_optin_mths',\n",
    "                                                     'msisdn','pmt_meth_cd','connection_dt','frst_cl_zone',\n",
    "                                                      'frst_cl_site_name','frst_cl_sales_cluster','frst_cl_region',\n",
    "                                                      'manufacturer','model','os','gadget_type','device_category',\n",
    "                                                      'smart_phone_flag','device_type','last_used_prev_monthend_dt',\n",
    "                                                      'last_used_monthend_dt','last_used_yearmonth_str',\n",
    "                                                       'success_count','ninety_count'], axis=1,errors='ignore'), test_size=0.2, random_state=113)\n",
    "\n",
    "# or\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(modelling_data_111[CANDIDATE_VARS]\n",
    "                               , test_size=0.5, random_state=113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[['target']] #\n",
    "y = y.astype('float')\n",
    "y = y.values.ravel()\n",
    "\n",
    "X = train.select_dtypes(include=['int64','int32','float','uint8'])\n",
    "X = X.drop([\"target\"], axis=1)\n",
    "\n",
    "y_test = test[['target']] #\n",
    "y_test = y_test.astype('float')\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "X_test = test.select_dtypes(include=['int64','int32','float','uint8'])\n",
    "X_test = X_test.drop([\"target\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m permutation_importance\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m### Feature importance using permutation\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m permutation_importance(\u001b[43mmodel\u001b[49m, X_test, y_test, n_repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m113\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m### The result has mean, std and and array of lower, median and upper bound of the values...\u001b[39;00m\n\u001b[0;32m      6\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(result\u001b[38;5;241m.\u001b[39mimportances_mean,index \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns,columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimportance\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimportance\u001b[39m\u001b[38;5;124m'\u001b[39m,ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "### Feature importance using permutation\n",
    "result = permutation_importance(model, X_test, y_test, n_repeats=3,random_state=113)\n",
    "### The result has mean, std and and array of lower, median and upper bound of the values...\n",
    "feature_importance = pd.DataFrame(result.importances_mean,index = X.columns,columns=['importance']).sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example of fitting a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(n_estimators=150, max_depth=4, use_label_encoder=False,eval_metric='logloss', random_state=113)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfc_predict_test = (model.predict_proba(X_test[X.columns])[:,1] >= 0.288).astype(bool)\n",
    "rfc_cv_score = cross_val_score(model, X_test[X.columns], y_test, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(\"=== Confusion Matrix : Test ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict_test))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict_test))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap.\n",
    "plt.figure(figsize=(24, 10))\n",
    "# Store heatmap object in a variable to easily access it when you want to include more features (such as title).\n",
    "# Set the range of values to be displayed on the colormap from -1 to 1, and set the annotation to True to display the correlation values on the heatmap.\n",
    "heatmap = sns.heatmap(X_test.corr(), vmin=-1, vmax=1, annot=True)\n",
    "# Give a title to the heatmap. Pad defines the distance of the title from the top of the heatmap.\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### ROC\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "fig = plot_roc_curve( model, X, y, name=\"train\")\n",
    "fig = plot_roc_curve( model, X_test, y_test, ax = fig.ax_, name=\"test\")\n",
    "#fig = plot_roc_curve( logRegModel, X_test_oot, y_test_oot, ax = fig.ax_, name=\"OOT Dates / name\")\n",
    "fig.figure_.suptitle(\"ROC curve comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probas = model.predict_proba(X_test)\n",
    "kds.metrics.plot_cumulative_gain(y_test, predicted_probas[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kds.metrics.plot_lift(y_test, predicted_probas[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
